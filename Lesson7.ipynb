{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec4cc250",
   "metadata": {},
   "source": [
    "# Lesson 7: Assessing the Off-Screen Gender Gap in Serial Production (Part 1)\n",
    "Date: November 30, 2023\n",
    "Duration: 3 hours\n",
    "\n",
    "In this lesson, we will explore the off-screen gender gap in serial production. We will delve into the basics of gender studies in media, learn how to scrape data from IMDb, and practice saving this data in a MongoDB database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be61d49",
   "metadata": {},
   "source": [
    "Certainly, here's an introduction text for the \"Introduction to Gender Studies in Media\" section of your course:\n",
    "\n",
    "---\n",
    "\n",
    "# Introduction to Gender Studies in Media\n",
    "\n",
    "Duration: 30 minutes\n",
    "\n",
    "---\n",
    "\n",
    "Welcome to this introductory session on Gender Studies in Media. In the next 30 minutes, we will embark on an explorative journey into the dynamic and complex world of gender representation in media. This session is designed to lay the foundation for understanding the pivotal role media plays in shaping and reflecting gender norms and perceptions in society.\n",
    "\n",
    "**Why Gender Studies in Media?**\n",
    "\n",
    "Gender studies in media is not just about analyzing who is seen and heard in media, but also about understanding the contexts, narratives, and roles assigned to different genders. It provides a lens through which we can critically examine the portrayal of gender identities, expressions, and relationships in various media forms, from films and television series to news and social media platforms.\n",
    "\n",
    "**Key Aspects of This Session:**\n",
    "\n",
    "1. **Conceptual Framework:** We will begin by defining key terms and concepts in gender studies, such as gender roles, stereotypes, and representation. Understanding these concepts is crucial for analyzing media content from a gendered perspective.\n",
    "\n",
    "2. **Historical Context:** A brief look at the evolution of gender representation in media over the decades will be provided. This historical perspective will help us appreciate the changes and continuities in gender portrayal.\n",
    "\n",
    "3. **Media's Impact on Society:** Media is a powerful tool that not only reflects but also shapes societal norms and values. We will discuss how media portrayal of gender can influence public opinion, reinforce stereotypes, or challenge existing norms.\n",
    "\n",
    "4. **Analyzing Contemporary Media:** We will look at examples from current media to understand how gender is represented in today's digital age. This will include discussions on diversity, inclusivity, and the emerging trends in gender representation.\n",
    "\n",
    "5. **Critical Engagement:** Finally, we will emphasize the importance of critical engagement with media. As media consumers and scholars, developing a critical eye towards media content allows us to be more informed and conscious viewers.\n",
    "\n",
    "This session aims to provide you with the tools and knowledge to critically analyze gender in media, encouraging you to question and engage with media content in more meaningful ways. Let's dive into the world of media and explore how it shapes, and is shaped by, our understanding of gender.\n",
    "\n",
    "---\n",
    "\n",
    "This introduction sets the stage for an engaging and insightful session, inviting students to critically examine and discuss the role of media in shaping gender perceptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fea77d",
   "metadata": {},
   "source": [
    "## IMDb Scraping Techniques\n",
    "Duration: 1 hour\n",
    "\n",
    "In this part, we will learn about different libraries and methods for scraping data from IMDb. This includes understanding the legal aspects, selecting the right tools, and implementing scraping techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ba1e2",
   "metadata": {},
   "source": [
    "https://www.imdb.com/search/title/\n",
    "\n",
    "https://www.imdb.com/search/title/?title_type=tv_series,tv_miniseries&genres=!animation,!news,!sport,!talk-show,!documentary&release_date=2008-01-01,2023-12-31&sort=moviemeter,asc&countries=IT&languages=it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ae4b9",
   "metadata": {},
   "source": [
    "### Guglielmo\n",
    "Serie TV_Mini serie TV, Data di uscita almeno 2020-01-01, Non Documentario, Non Cortometraggio, Italia, Italiano (Ordinati per Popolarità Crescente).html\n",
    "File\n",
    "The html page I loaded for you contains the first 50 titles of 404 television series. Each title corresponds to a link in the format https://www.imdb.com/title/tt28019928/?ref_=sr_t_1 \n",
    "I need you to extract the code (e.g., tt28019928) for each title and add it to a csv file.\n",
    "I then need you to scroll to the next 50 through the \"altri 50\" button at the bottom of the page and repeat the operation of saving the codes for all new titles.\n",
    "Continue until you have saved the codes for all 404 titles.\n",
    "### ChatGPT\n",
    "\n",
    "I have extracted the IMDB codes from the first set of TV series titles in the HTML page you provided. The codes have been saved to a CSV file. You can download the file using the link below:\n",
    "\n",
    "Download the CSV file with IMDB codes\n",
    "\n",
    "To continue with the next 50 titles, I'll need to access the next page. Could you please provide the HTML page after clicking the \"altri 50\" button? This will allow me to extract the codes for the subsequent titles. ​\n",
    "\n",
    "​\n",
    "### Guglielmo\n",
    "There are no codes in your file, please control\n",
    "### ChatGPT\n",
    "\n",
    "It seems that the approach to extract IMDB codes from the HTML content is not yielding results. This could be due to the structure of the HTML not aligning with the expected format, or the relevant data might be loaded dynamically and not present in the static HTML file.\n",
    "\n",
    "To proceed, I will inspect the HTML content directly to understand its structure and find the correct way to extract the IMDB codes. Let's look at a portion of the HTML content to identify the relevant patterns. ​\n",
    "\n",
    "​\n",
    "\n",
    "The initial portion of the HTML content does not reveal the structure or patterns needed to extract the IMDB codes. Given the complexity and possible variations in the HTML structure, it would be beneficial to inspect the specific sections of the HTML where the TV series titles and their corresponding IMDB codes are likely to be listed.\n",
    "\n",
    "I will now search for patterns that typically denote links or identifiers in HTML, such as <a href=...>, to locate the relevant section. Let's examine another part of the HTML content for this purpose. ​\n",
    "\n",
    "​\n",
    "\n",
    "The extracted portion of the HTML content still does not reveal the specific structure for the IMDB codes. It appears that the content might be heavily scripted or dynamically loaded, which makes it challenging to extract the data from a static HTML file.\n",
    "\n",
    "To accurately extract the IMDB codes, I would need either:\n",
    "\n",
    "    A different portion of the HTML that includes the section where the TV series titles and IMDB codes are listed.\n",
    "    Access to the web page in a dynamic environment where the scripted content is fully loaded.\n",
    "\n",
    "If you can provide another portion of the HTML file or access to the dynamic page, I will attempt the extraction again. ​\n",
    "\n",
    "​\n",
    "\n",
    "### Guglielmo\n",
    "    \n",
    "https://www.imdb.com/search/title/?title_type=tv_series,tv_miniseries&genres=!documentary,!short&release_date=2020-01-01,&country_of_origin=IT&languages=it\n",
    "### ChatGPT\n",
    "\n",
    "I attempted to retrieve the IMDB codes directly from the URL you provided. However, due to the limitations of my current environment, I am unable to access external websites, including IMDb.\n",
    "\n",
    "To proceed, I would recommend manually accessing the IMDb page and saving the HTML content of each page after clicking the \"altri 50\" button. You can then upload these HTML files here, and I will extract the IMDB codes from them. ​\n",
    "\n",
    "​\n",
    "### Guglielmo\n",
    "    <a class=\"ipc-lockup-overlay ipc-focusable\" href=\"https://www.imdb.com/title/tt28019928/?ref_=sr_i_1\" aria-label=\"Visualizza la pagina del titolo di Suburræterna\"><div class=\"ipc-lockup-overlay__screen\">\n",
    "\n",
    "### ChatGPT\n",
    "Thank you for providing a sample of the HTML structure. Based on this, I can create a script to extract the IMDB codes from the links. I will parse the HTML content again using this structure as a reference. Let's proceed with the extraction.\n",
    "\n",
    "The extraction was successful using the provided HTML structure. I have extracted a total of 50 IMDB codes from the page.\n",
    "\n",
    "To continue with the extraction for the remaining titles, I will need the HTML content of the subsequent pages after clicking the \"altri 50\" button. You can upload these HTML files, and I will repeat the extraction process for each page. ​\n",
    "\n",
    "​\n",
    "### Guglielmo\n",
    "Give me the csv with the codes\n",
    "### ChatGPT\n",
    "\n",
    "The IMDB codes have been saved to a CSV file. You can download the file using the following link:\n",
    "\n",
    "Download the CSV file with IMDB codes\n",
    "\n",
    "If you have additional HTML pages for the subsequent titles, you can upload them, and I will extract the remaining IMDB codes. ​\n",
    "\n",
    "​\n",
    "### Guglielmo\n",
    "Can you give me the code you used?\n",
    "### ChatGPT\n",
    "\n",
    "Here is the Python code I used for extracting the IMDB codes from the HTML content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract IMDB codes from an HTML file\n",
    "def extract_imdb_codes_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    imdb_codes = []\n",
    "    for a_tag in soup.find_all('a', href=True, class_='ipc-lockup-overlay ipc-focusable'):\n",
    "        href = a_tag.get('href', '')\n",
    "        if 'title/tt' in href:\n",
    "            code = href.split('/title/')[1].split('/')[0]\n",
    "            imdb_codes.append(code)\n",
    "    return imdb_codes\n",
    "\n",
    "# Example usage\n",
    "file_path = '/path/to/your/html/file.html'  # Replace with the path to your HTML file\n",
    "imdb_codes = extract_imdb_codes_from_file(file_path)\n",
    "\n",
    "# Saving the extracted codes to a CSV file\n",
    "df = pd.DataFrame({'IMDB_Code': imdb_codes})\n",
    "df.to_csv('imdb_codes.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c076c351",
   "metadata": {},
   "source": [
    "### Guglielmo\n",
    "Okay, the script works fine. As you figured out, the IMDb page shows the first 50 results. To get them all you have to click the \"50 more\" button so that another 50 titles are added to the page and then to continue until you have all the titles on the same page. Please note that the search result is not divided into pages of 50 titles, the titles are added on the same page.\n",
    "To get my code list I used this strategy: I clicked on the \"50 more\" button until I had all the results on one page, saved it, and parsed it with your script.\n",
    "Now I would like to automate the process: have a script that automatically clicks the button until I have the page with all the results and then continues with the script we already have.\n",
    "### ChatGPT\n",
    "\n",
    "To automate the process of clicking the \"50 more\" button on the IMDb page until all the results are loaded, and then extracting the IMDB codes, you would need a script that combines web scraping with web automation. Python's Selenium library is well-suited for this task, as it allows you to control a web browser programmatically, including simulating clicks on web page elements.\n",
    "\n",
    "Here's a high-level overview of how you can do this:\n",
    "\n",
    "    Setup Selenium: Install Selenium and a WebDriver for the browser you want to use (like ChromeDriver for Google Chrome).\n",
    "\n",
    "    Load the IMDb Page: Use Selenium to open the IMDb search results page in a browser.\n",
    "\n",
    "    Click the \"50 more\" Button: Write a loop that repeatedly finds and clicks the \"50 more\" button until all results are loaded. You would need to implement a mechanism to detect when you've reached the end of the results.\n",
    "\n",
    "    Extract the HTML Content: Once all results are loaded, you can extract the entire HTML content of the page.\n",
    "\n",
    "    Parse and Extract IMDB Codes: Use Beautiful Soup (or Selenium's parsing capabilities) to extract the IMDB codes from the HTML content.\n",
    "\n",
    "    Save to a CSV File: Save the extracted codes to a CSV file as you've done before.\n",
    "\n",
    "Here's a basic implementation in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bae81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract IMDB codes from an HTML file\n",
    "def extract_imdb_codes_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    imdb_codes = []\n",
    "    for a_tag in soup.find_all('a', href=True, class_='ipc-lockup-overlay ipc-focusable'):\n",
    "        href = a_tag.get('href', '')\n",
    "        if 'title/tt' in href:\n",
    "            code = href.split('/title/')[1].split('/')[0]\n",
    "            imdb_codes.append(code)\n",
    "    return imdb_codes\n",
    "\n",
    "# Example usage\n",
    "file_path = '/path/to/your/html/file.html'  # Replace with the path to your HTML file\n",
    "imdb_codes = extract_imdb_codes_from_file(file_path)\n",
    "\n",
    "# Saving the extracted codes to a CSV file\n",
    "df = pd.DataFrame({'IMDB_Code': imdb_codes})\n",
    "df.to_csv('imdb_codes.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b4d2e",
   "metadata": {},
   "source": [
    "in this modified code, replace '/path/to/your/html/file.html' with the actual path to your HTML file. This code opens the HTML file, reads its content, and then passes the content to Beautiful Soup for parsing and extracting the IMDB codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ce3a0",
   "metadata": {},
   "source": [
    "### Guglielmo\n",
    "Okay, the script works fine. As you figured out, the IMDb page shows the first 50 results. To get them all you have to click the \"50 more\" button so that another 50 titles are added to the page and then to continue until you have all the titles on the same page. Please note that the search result is not divided into pages of 50 titles, the titles are added on the same page.\n",
    "To get my code list I used this strategy: I clicked on the \"50 more\" button until I had all the results on one page, saved it, and parsed it with your script.\n",
    "Now I would like to automate the process: have a script that automatically clicks the button until I have the page with all the results and then continues with the script we already have.\n",
    "### ChatGPT\n",
    "\n",
    "To automate the process of clicking the \"50 more\" button on the IMDb page until all the results are loaded, and then extracting the IMDB codes, you would need a script that combines web scraping with web automation. Python's Selenium library is well-suited for this task, as it allows you to control a web browser programmatically, including simulating clicks on web page elements.\n",
    "\n",
    "Here's a high-level overview of how you can do this:\n",
    "\n",
    "    Setup Selenium: Install Selenium and a WebDriver for the browser you want to use (like ChromeDriver for Google Chrome).\n",
    "\n",
    "    Load the IMDb Page: Use Selenium to open the IMDb search results page in a browser.\n",
    "\n",
    "    Click the \"50 more\" Button: Write a loop that repeatedly finds and clicks the \"50 more\" button until all results are loaded. You would need to implement a mechanism to detect when you've reached the end of the results.\n",
    "\n",
    "    Extract the HTML Content: Once all results are loaded, you can extract the entire HTML content of the page.\n",
    "\n",
    "    Parse and Extract IMDB Codes: Use Beautiful Soup (or Selenium's parsing capabilities) to extract the IMDB codes from the HTML content.\n",
    "\n",
    "    Save to a CSV File: Save the extracted codes to a CSV file as you've done before.\n",
    "\n",
    "Here's a basic implementation in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84be5a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Function to convert number string with commas or periods to an integer\n",
    "def convert_to_int(num_str):\n",
    "    return int(num_str.replace(',', '').replace('.', ''))\n",
    "\n",
    "# Selenium setup\n",
    "driver = webdriver.Chrome('/path/to/chromedriver')  # Specify the path to chromedriver\n",
    "\n",
    "# Load the IMDb page\n",
    "driver.get('IMDb URL')  # Replace with your IMDb URL\n",
    "\n",
    "# Wait for the initial page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Extract the total number of results\n",
    "total_results_str = driver.find_element_by_css_selector('CSS Selector for total results element').text.split()[-1]\n",
    "total_results = convert_to_int(total_results_str)\n",
    "\n",
    "loaded_results = 0\n",
    "# Click the \"50 more\" button until all results are loaded\n",
    "while loaded_results < total_results:\n",
    "    try:\n",
    "        load_more_button = driver.find_element_by_xpath('XPATH of the button')  # Replace with the actual XPATH\n",
    "        load_more_button.click()\n",
    "        time.sleep(5)  # Wait for the page to load more results\n",
    "        loaded_results = int(driver.find_element_by_css_selector('CSS Selector for loaded results element').text.split('-')[-1].split()[0])\n",
    "    except Exception as e:\n",
    "        print(\"All results loaded or an error occurred:\", e)\n",
    "        break\n",
    "\n",
    "# Extract the HTML content\n",
    "html_content = driver.page_source\n",
    "\n",
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "imdb_codes = [tag.get('href').split('/')[2].split('?')[0] for tag in soup.find_all('a', href=True) if 'title/tt' in tag.get('href')]\n",
    "\n",
    "# Save the IMDB codes to a CSV file\n",
    "df = pd.DataFrame({'IMDB_Code': imdb_codes})\n",
    "df.to_csv('imdb_codes.csv', index=False)\n",
    "\n",
    "# Close the Selenium browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8182c84",
   "metadata": {},
   "source": [
    "In this script, you need to replace:\n",
    "\n",
    "    'IMDb URL' with the actual URL of the IMDb page.\n",
    "    'XPATH of the button' with the XPath of the \"50 more\" button.\n",
    "    'CSS Selector for total results element' and 'CSS Selector for loaded results element' with the appropriate CSS selectors for the total number of results and the number of results currently loaded, respectively.\n",
    "\n",
    "This script will keep clicking the \"50 more\" button until the number of loaded results matches the total number of results, and then it will extract and save the IMDB codes.\n",
    "\n",
    "### Guglielmo\n",
    "How I find the CSS selectors? \n",
    "\n",
    "### ChatGPT\n",
    "\n",
    "To find the CSS selectors for elements on a web page, you can use the browser's Developer Tools. Here's a general guide on how to do this:\n",
    "\n",
    "    Open the IMDb page in your browser: Navigate to the specific IMDb page where you need to find the CSS selector.\n",
    "\n",
    "    Open Developer Tools:\n",
    "        On Chrome, Firefox, or Edge, you can right-click on the page and select \"Inspect\" or press Ctrl + Shift + I (Cmd + Option + I on Mac).\n",
    "        On Safari, first enable the Develop menu from Safari's Advanced preferences, then right-click on the page and select \"Inspect Element\".\n",
    "\n",
    "    Locate the Element:\n",
    "        Use the \"Select element\" tool in the Developer Tools (usually an icon with a mouse cursor and a rectangle) to click on the element you're interested in. This could be the text that shows the number of results or the \"50 more\" button.\n",
    "        Alternatively, you can manually navigate through the HTML in the \"Elements\" tab to find the desired element.\n",
    "\n",
    "    Identify the CSS Selector:\n",
    "        Once you've selected an element, the HTML will be highlighted in the Elements tab.\n",
    "        Right-click the highlighted HTML, then go to \"Copy\" and choose \"Copy selector\" or \"Copy CSS path\" (the option name may vary slightly depending on your browser).\n",
    "\n",
    "    Test the CSS Selector:\n",
    "        You can test the copied selector in the console of the Developer Tools by using a query like document.querySelector('your-copied-selector') to see if it returns the correct element.\n",
    "\n",
    "Remember, the CSS selector you obtain is specific to the structure of the page at the time you inspect it. If the website's layout changes in the future, the selector might need to be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da0aa08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0fefb8b",
   "metadata": {},
   "source": [
    "## Saving Data in MongoDB\n",
    "Duration: 1 hour\n",
    "\n",
    "After collecting data from IMDb, we will focus on setting up a MongoDB database and saving our scraped data. This includes database setup, schema design, and data entry processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6594a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "464eec36",
   "metadata": {},
   "source": [
    "## Q&A and Discussion\n",
    "Duration: 30 minutes\n",
    "\n",
    "The final part of this lesson is reserved for a question and answer session, where students can clarify doubts and discuss the topics covered in today's class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
